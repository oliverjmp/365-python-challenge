### ü§ñ Proyecto D√≠a 47: Web Scraping Foundations üåêüï∑Ô∏è

Hoy iniciamos la extracci√≥n automatizada de datos externos. El objetivo es aprender a realizar peticiones HTTP seguras y parsear el c√≥digo fuente de una web para convertir texto desordenado en datos estructurados.

#### **Hitos T√©cnicos Alcanzados:**
1.  **Protocolo HTTP con `requests`:** Gesti√≥n de peticiones GET y manejo de c√≥digos de estado (200 OK, 404 Not Found).
2.  **Parsing de HTML con `BeautifulSoup`:** Navegaci√≥n por el DOM (Document Object Model) para localizar etiquetas espec√≠ficas (`h1`, `p`, `a`).
3.  **User-Agent Spoofing:** Configuraci√≥n de cabeceras para que nuestra petici√≥n parezca provenir de un navegador real, evitando bloqueos b√°sicos.
4.  **Extracci√≥n Selectiva:** Filtrado de elementos por ID y Clase para obtener informaci√≥n precisa sin ruido.

#### **Tecnolog√≠as Utilizadas:**
* **Requests:** La librer√≠a est√°ndar de facto para peticiones HTTP.
* **BeautifulSoup4:** Para navegar y buscar dentro del √°rbol HTML.
* **LXML:** Parser de alto rendimiento para procesar el HTML.